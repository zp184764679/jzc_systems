# GPU åŠ é€Ÿå®‰è£…æŒ‡å—

## ğŸ¯ å½“å‰çŠ¶æ€
- **PyTorch**: `2.8.0+cpu` âŒ CPUç‰ˆæœ¬
- **PaddlePaddle**: `3.2.1` âŒ å¯èƒ½æ˜¯CPUç‰ˆæœ¬
- **CUDA**: æœªæ£€æµ‹åˆ°

---

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. æ£€æŸ¥æ˜¾å¡
```bash
# æ‰“å¼€è®¾å¤‡ç®¡ç†å™¨ -> æ˜¾ç¤ºé€‚é…å™¨
# æˆ–è¿è¡Œï¼š
nvidia-smi
```

ç¡®è®¤ä½ çš„NVIDIAæ˜¾å¡å‹å·å’Œé©±åŠ¨ç‰ˆæœ¬ã€‚

### 2. å®‰è£… CUDA Toolkit

**æ¨èç‰ˆæœ¬**: CUDA 12.1 æˆ– 12.4

ä¸‹è½½åœ°å€ï¼šhttps://developer.nvidia.com/cuda-downloads

```bash
# éªŒè¯å®‰è£…
nvcc --version
nvidia-smi
```

---

## ğŸš€ å®‰è£… GPU ç‰ˆæœ¬

### Step 1: å¸è½½ CPU ç‰ˆæœ¬

```bash
cd C:\Users\Admin\Desktop\é‡‡è´­\backend

# å¸è½½CPUç‰ˆPyTorch
pip uninstall torch torchvision torchaudio

# å¸è½½PaddlePaddle
pip uninstall paddlepaddle
```

### Step 2: å®‰è£… GPU ç‰ˆ PyTorch

```bash
# PyTorch 2.8.0 + CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# æˆ– CUDA 12.4
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

**éªŒè¯å®‰è£…**:
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"Device name: {torch.cuda.get_device_name(0)}")
```

### Step 3: å®‰è£… GPU ç‰ˆ PaddlePaddle

```bash
# CUDA 12.3
pip install paddlepaddle-gpu==3.2.1 -i https://mirror.baidu.com/pypi/simple

# æˆ–ä»å®˜ç½‘é€‰æ‹©ç‰ˆæœ¬ï¼š
# https://www.paddlepaddle.org.cn/install/quick
```

**éªŒè¯å®‰è£…**:
```python
import paddle
print(f"Paddle compiled with CUDA: {paddle.is_compiled_with_cuda()}")
print(f"GPU count: {paddle.device.cuda.device_count()}")
```

---

## âš¡ Ollama GPU åŠ é€Ÿ

### å®‰è£… Ollamaï¼ˆå·²æ”¯æŒGPUï¼‰

```bash
# Windows ä¸‹è½½
https://ollama.com/download/windows

# å®‰è£…åå¯åŠ¨
ollama serve

# æ‹‰å–æ¨¡å‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨GPUï¼‰
ollama pull qwen2.5:7b
```

### éªŒè¯ GPU ä½¿ç”¨

```bash
# è¿è¡Œæ¨¡å‹æ—¶æŸ¥çœ‹GPUä½¿ç”¨
nvidia-smi

# åº”è¯¥çœ‹åˆ° ollama.exe å ç”¨GPUæ˜¾å­˜
```

---

## ğŸ”§ é…ç½®æ£€æŸ¥æ¸…å•

### âœ… å®Œæˆåæ£€æŸ¥

1. **PyTorch GPU**:
```bash
python -c "import torch; print(torch.cuda.is_available())"
# è¾“å‡º: True
```

2. **PaddlePaddle GPU**:
```bash
python -c "import paddle; print(paddle.device.cuda.device_count())"
# è¾“å‡º: 1 (æˆ–ä½ çš„GPUæ•°é‡)
```

3. **Ollama**:
```bash
curl http://localhost:11434/api/tags
# åº”è¿”å›æ¨¡å‹åˆ—è¡¨
```

4. **é‡å¯åç«¯ï¼ŒæŸ¥çœ‹æ—¥å¿—**:
```bash
cd C:\Users\Admin\Desktop\é‡‡è´­\backend
python app.py

# åº”è¯¥çœ‹åˆ°ï¼š
# âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ (Device: GPU (NVIDIA GeForce RTX ...))
# âœ… Ollama åç«¯åˆå§‹åŒ–æˆåŠŸ
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç»„ä»¶ | CPU | GPU | åŠ é€Ÿæ¯” |
|------|-----|-----|--------|
| PaddleOCR å‘ç¥¨è¯†åˆ« | ~2-3ç§’ | ~0.3-0.5ç§’ | 5-10x |
| Ollama AIåˆ†ç±» | ~5-10ç§’ | ~0.5-1ç§’ | 10-20x |
| æ€»ä½“ç”¨æˆ·ä½“éªŒ | æ…¢ ğŸ˜ | æµç•… ğŸš€ | - |

---

## âš ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜1: `torch.cuda.is_available()` è¿”å› False

**å¯èƒ½åŸå› **:
1. CUDAé©±åŠ¨ç‰ˆæœ¬ä¸åŒ¹é…
2. PyTorchå’ŒCUDAç‰ˆæœ¬ä¸åŒ¹é…
3. ç¯å¢ƒå˜é‡æœªè®¾ç½®

**è§£å†³**:
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version
nvidia-smi  # æŸ¥çœ‹CUDA Driver Version

# é‡æ–°å®‰è£…åŒ¹é…ç‰ˆæœ¬çš„PyTorch
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### é—®é¢˜2: PaddleOCR ä»ä½¿ç”¨CPU

**æ£€æŸ¥**:
```python
import paddle
print(paddle.device.get_device())  # åº”è¾“å‡º 'gpu:0'
```

**å¼ºåˆ¶ä½¿ç”¨GPU**:
```python
paddle.device.set_device('gpu:0')
```

### é—®é¢˜3: Ollama GPUæ˜¾å­˜ä¸è¶³

**è§£å†³**: å‡å°‘æ¨¡å‹å¤§å°
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull qwen2.5:3b  # 3Bå‚æ•° (æ›¿ä»£ 7B)
```

---

## ğŸ¯ æ¨èé…ç½®

**æœ€ä½³æ€§èƒ½**:
- CUDA 12.1+
- PyTorch 2.8.0 GPU
- PaddlePaddle 3.2.1 GPU
- Ollama + qwen2.5:7b (GPU)

**æœ€ä½è¦æ±‚**:
- NVIDIA GPU (4GB+ æ˜¾å­˜)
- CUDA 11.8+
- å¯¹åº”çš„GPUç‰ˆæœ¬åº“

---

å®Œæˆä¸Šè¿°æ­¥éª¤åï¼Œä½ çš„AI/OCRç»„ä»¶å°†å…¨éƒ¨è¿è¡Œåœ¨GPUä¸Šï¼Œæ€§èƒ½æå‡5-20å€ï¼ğŸš€
