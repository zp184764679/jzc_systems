# services/ocr_learning_service.py
"""
OCRå­¦ä¹ ä¼˜åŒ–æœåŠ¡
å®ç°æ™ºèƒ½è§„åˆ™éªŒè¯å’ŒPromptåŠ¨æ€ä¼˜åŒ–
"""
from typing import Dict, List, Optional, Tuple
from sqlalchemy.orm import Session
from models.ocr_correction import OCRCorrection
from difflib import SequenceMatcher
import re
import logging

logger = logging.getLogger(__name__)

# å»¶è¿Ÿå¯¼å…¥å‘é‡å­˜å‚¨æœåŠ¡ï¼Œé¿å…å¾ªç¯ä¾èµ–
_vector_store_service = None

def _get_vector_store():
    """å»¶è¿Ÿè·å–å‘é‡å­˜å‚¨æœåŠ¡"""
    global _vector_store_service
    if _vector_store_service is None:
        try:
            from services.vector_store_service import get_vector_store_service
            _vector_store_service = get_vector_store_service()
        except Exception as e:
            logger.warning(f"âš ï¸  å‘é‡å­˜å‚¨æœåŠ¡ä¸å¯ç”¨: {e}")
    return _vector_store_service


class OCRLearningService:
    """OCRæ™ºèƒ½å­¦ä¹ æœåŠ¡"""

    # æ™ºèƒ½è§„åˆ™åº“
    SMART_RULES = {
        # ææ–™æ ‡å‡†åŒ–è§„åˆ™
        'material': {
            'patterns': [
                (r'sus\s*303', 'SUS303', re.IGNORECASE),
                (r'sus\s*304', 'SUS304', re.IGNORECASE),
                (r'45\s*#', '45#', re.IGNORECASE),
                (r'45å·é’¢', '45#', re.IGNORECASE),
                (r'6061\s*é“', '6061é“åˆé‡‘', re.IGNORECASE),
                (r's45c', 'S45C', re.IGNORECASE),
                (r'stainless\s*steel', 'ä¸é”ˆé’¢', re.IGNORECASE),
            ],
            'validator': lambda x: x and len(x.strip()) > 0
        },

        # ç›´å¾„æ•°å€¼è§„åˆ™ï¼ˆæ¸…ç†éæ•°å­—å­—ç¬¦ï¼‰
        'outer_diameter': {
            'patterns': [
                (r'[Ï†Î¦Ã˜]\s*(\d+\.?\d*)', r'\1', 0),  # ç§»é™¤ç›´å¾„ç¬¦å·
                (r'(\d+\.?\d*)\s*mm', r'\1', re.IGNORECASE),  # ç§»é™¤å•ä½
            ],
            'validator': lambda x: x and re.match(r'^\d+\.?\d*$', str(x))
        },

        # é•¿åº¦æ•°å€¼è§„åˆ™
        'length': {
            'patterns': [
                (r'(\d+\.?\d*)\s*mm', r'\1', re.IGNORECASE),
                (r'é•¿åº¦?\s*[:ï¼š]?\s*(\d+\.?\d*)', r'\1', re.IGNORECASE),
            ],
            'validator': lambda x: x and re.match(r'^\d+\.?\d*$', str(x))
        },

        # å…¬å·®è§„åˆ™
        'tolerance': {
            'patterns': [
                (r'[Â±]\s*(\d+\.?\d*)', r'Â±\1', 0),
                (r'IT\s*(\d+)', r'IT\1', re.IGNORECASE),
                (r'H\s*(\d+)', r'H\1', re.IGNORECASE),
            ],
            'validator': lambda x: x and (re.match(r'Â±\d+\.?\d*', str(x)) or re.match(r'IT\d+', str(x), re.IGNORECASE) or re.match(r'H\d+', str(x), re.IGNORECASE))
        },

        # è¡¨é¢ç²—ç³™åº¦è§„åˆ™
        'surface_roughness': {
            'patterns': [
                (r'Ra\s*(\d+\.?\d*)', r'Ra\1', re.IGNORECASE),
                (r'â–½\s*(\d+\.?\d*)', r'Ra\1', 0),
            ],
            'validator': lambda x: x and re.match(r'Ra\d+\.?\d*', str(x), re.IGNORECASE)
        },
    }

    def __init__(self, db: Session):
        self.db = db

    def apply_smart_rules(self, ocr_data: Dict) -> Dict:
        """
        åº”ç”¨æ™ºèƒ½è§„åˆ™å¯¹OCRç»“æœè¿›è¡Œè‡ªåŠ¨ä¿®æ­£

        Args:
            ocr_data: OCRè¯†åˆ«çš„åŸå§‹æ•°æ®

        Returns:
            ä¿®æ­£åçš„æ•°æ®å­—å…¸
        """
        corrected_data = ocr_data.copy()
        corrections_applied = []

        for field_name, rules in self.SMART_RULES.items():
            if field_name not in corrected_data or not corrected_data[field_name]:
                continue

            original_value = str(corrected_data[field_name])
            corrected_value = original_value

            # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢è§„åˆ™
            for pattern, replacement, flags in rules.get('patterns', []):
                corrected_value = re.sub(pattern, replacement, corrected_value, flags=flags)

            # éªŒè¯ä¿®æ­£åçš„å€¼
            validator = rules.get('validator')
            if validator and not validator(corrected_value):
                # éªŒè¯å¤±è´¥ï¼Œä¿æŒåŸå€¼
                continue

            # å¦‚æœå€¼å‘ç”Ÿäº†å˜åŒ–ï¼Œè®°å½•ä¿®æ­£
            if corrected_value != original_value:
                corrected_data[field_name] = corrected_value
                corrections_applied.append({
                    'field': field_name,
                    'original': original_value,
                    'corrected': corrected_value,
                    'rule': 'smart_rule'
                })
                logger.info(f"ğŸ¤– æ™ºèƒ½è§„åˆ™ä¿®æ­£ [{field_name}]: '{original_value}' â†’ '{corrected_value}'")

        corrected_data['_auto_corrections'] = corrections_applied
        return corrected_data

    def record_correction(
        self,
        drawing_id: int,
        field_name: str,
        ocr_value: Optional[str],
        corrected_value: str
    ) -> OCRCorrection:
        """
        è®°å½•äººå·¥ä¿®æ­£æ•°æ®

        Args:
            drawing_id: å›¾çº¸ID
            field_name: å­—æ®µå
            ocr_value: OCRè¯†åˆ«çš„åŸå§‹å€¼
            corrected_value: äººå·¥ä¿®æ­£åçš„å€¼

        Returns:
            OCRCorrectionè®°å½•
        """
        # è®¡ç®—ä¿®æ­£ç±»å‹å’Œç›¸ä¼¼åº¦
        correction_type, similarity = self._analyze_correction(ocr_value, corrected_value)

        correction = OCRCorrection(
            drawing_id=drawing_id,
            field_name=field_name,
            ocr_value=ocr_value,
            corrected_value=corrected_value,
            correction_type=correction_type,
            similarity_score=similarity
        )

        self.db.add(correction)
        self.db.commit()

        logger.info(f"ğŸ“ è®°å½•ä¿®æ­£: [{field_name}] {ocr_value} â†’ {corrected_value} (ç±»å‹: {correction_type}, ç›¸ä¼¼åº¦: {similarity:.2f})")

        # åŒæ­¥åˆ°å‘é‡åº“ï¼ˆæ–¹æ¡ˆCï¼‰
        try:
            vector_store = _get_vector_store()
            if vector_store:
                vector_store.add_correction(correction)
                logger.info(f"âœ… ä¿®æ­£å·²åŒæ­¥åˆ°å‘é‡åº“")
        except Exception as e:
            logger.warning(f"âš ï¸  å‘é‡åº“åŒæ­¥å¤±è´¥: {e}")

        return correction

    def _analyze_correction(
        self,
        ocr_value: Optional[str],
        corrected_value: str
    ) -> Tuple[str, float]:
        """
        åˆ†æä¿®æ­£ç±»å‹å’Œç›¸ä¼¼åº¦

        Returns:
            (correction_type, similarity_score)
        """
        if not ocr_value or ocr_value.strip() == '':
            return ('full_error', 0.0)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, str(ocr_value), str(corrected_value)).ratio()

        # åˆ¤æ–­ä¿®æ­£ç±»å‹
        if similarity < 0.3:
            return ('full_error', similarity)
        elif similarity < 0.7:
            return ('partial_error', similarity)
        else:
            return ('format_error', similarity)

    def get_correction_stats(
        self,
        field_name: Optional[str] = None,
        limit: int = 100
    ) -> Dict:
        """
        è·å–ä¿®æ­£ç»Ÿè®¡æ•°æ®

        Args:
            field_name: å¯é€‰ï¼ŒæŒ‡å®šå­—æ®µå
            limit: è¿”å›çš„æœ€å¤§è®°å½•æ•°

        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        query = self.db.query(OCRCorrection)

        if field_name:
            query = query.filter(OCRCorrection.field_name == field_name)

        corrections = query.order_by(OCRCorrection.created_at.desc()).limit(limit).all()

        # ç»Ÿè®¡åˆ†æ
        total = len(corrections)
        if total == 0:
            return {
                'total': 0,
                'by_field': {},
                'by_type': {},
                'avg_similarity': 0
            }

        by_field = {}
        by_type = {}
        total_similarity = 0

        for correction in corrections:
            # æŒ‰å­—æ®µç»Ÿè®¡
            if correction.field_name not in by_field:
                by_field[correction.field_name] = 0
            by_field[correction.field_name] += 1

            # æŒ‰ç±»å‹ç»Ÿè®¡
            if correction.correction_type not in by_type:
                by_type[correction.correction_type] = 0
            by_type[correction.correction_type] += 1

            # ç´¯è®¡ç›¸ä¼¼åº¦
            total_similarity += correction.similarity_score or 0

        return {
            'total': total,
            'by_field': by_field,
            'by_type': by_type,
            'avg_similarity': total_similarity / total if total > 0 else 0,
            'recent_corrections': [
                {
                    'field': c.field_name,
                    'ocr_value': c.ocr_value,
                    'corrected_value': c.corrected_value,
                    'type': c.correction_type,
                    'similarity': c.similarity_score,
                    'created_at': c.created_at.isoformat()
                }
                for c in corrections[:20]  # æœ€è¿‘20æ¡
            ]
        }

    def learn_from_corrections(self) -> Dict:
        """
        ä»ä¿®æ­£æ•°æ®ä¸­å­¦ä¹ ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®

        Returns:
            åŒ…å«å­¦ä¹ ç»“æœå’Œä¼˜åŒ–å»ºè®®çš„å­—å…¸
        """
        stats = self.get_correction_stats(limit=500)

        if stats['total'] < 10:
            return {
                'status': 'insufficient_data',
                'message': f'ä¿®æ­£æ•°æ®ä¸è¶³ï¼ˆå½“å‰: {stats["total"]}ï¼Œéœ€è¦è‡³å°‘10æ¡ï¼‰',
                'suggestions': []
            }

        suggestions = []

        # åˆ†æé«˜é¢‘é”™è¯¯å­—æ®µ
        for field_name, count in stats['by_field'].items():
            if count > stats['total'] * 0.2:  # å æ¯”è¶…è¿‡20%
                suggestions.append({
                    'type': 'high_error_field',
                    'field': field_name,
                    'count': count,
                    'suggestion': f'å­—æ®µ {field_name} é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–Promptä¸­çš„ç›¸å…³æè¿°'
                })

        # åˆ†æé”™è¯¯ç±»å‹åˆ†å¸ƒ
        full_errors = stats['by_type'].get('full_error', 0)
        if full_errors > stats['total'] * 0.3:  # å®Œå…¨é”™è¯¯è¶…è¿‡30%
            suggestions.append({
                'type': 'high_full_error_rate',
                'count': full_errors,
                'suggestion': 'OCRå®Œå…¨è¯†åˆ«é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®å¢å¼ºæ¨¡å‹çš„å›¾çº¸ç†è§£èƒ½åŠ›æˆ–è°ƒæ•´å¸ƒå±€åˆ†æ'
            })

        # å¹³å‡ç›¸ä¼¼åº¦åˆ†æ
        if stats['avg_similarity'] < 0.5:
            suggestions.append({
                'type': 'low_similarity',
                'avg_similarity': stats['avg_similarity'],
                'suggestion': f'å¹³å‡ç›¸ä¼¼åº¦è¾ƒä½ ({stats["avg_similarity"]:.2f})ï¼Œå»ºè®®å…¨é¢ä¼˜åŒ–OCRæ¨¡å‹'
            })

        return {
            'status': 'success',
            'stats': stats,
            'suggestions': suggestions
        }

    def get_field_patterns(self, field_name: str, min_count: int = 3) -> List[Dict]:
        """
        æå–æŸä¸ªå­—æ®µçš„å¸¸è§ä¿®æ­£æ¨¡å¼

        Args:
            field_name: å­—æ®µå
            min_count: æœ€å°å‡ºç°æ¬¡æ•°

        Returns:
            æ¨¡å¼åˆ—è¡¨
        """
        corrections = self.db.query(OCRCorrection).filter(
            OCRCorrection.field_name == field_name
        ).all()

        # ç»Ÿè®¡OCRå€¼åˆ°ä¿®æ­£å€¼çš„æ˜ å°„
        pattern_map = {}
        for c in corrections:
            key = (c.ocr_value or '', c.corrected_value or '')
            if key not in pattern_map:
                pattern_map[key] = 0
            pattern_map[key] += 1

        # è¿‡æ»¤å‡ºé«˜é¢‘æ¨¡å¼
        patterns = [
            {
                'ocr_value': ocr_val,
                'corrected_value': corrected_val,
                'count': count
            }
            for (ocr_val, corrected_val), count in pattern_map.items()
            if count >= min_count
        ]

        # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
        patterns.sort(key=lambda x: x['count'], reverse=True)

        return patterns


    def auto_correct_ocr_result(self, ocr_data: Dict, min_count: int = 3) -> Dict:
        """
        è‡ªåŠ¨åº”ç”¨é«˜é¢‘ä¿®æ­£æ¨¡å¼åˆ°OCRç»“æœï¼ˆæ–¹æ¡ˆAæ ¸å¿ƒåŠŸèƒ½ï¼‰

        åŸç†ï¼š
        - æŸ¥è¯¢å†å²ä¿®æ­£è®°å½•
        - å¦‚æœæŸä¸ªä¿®æ­£å‡ºç°è¶…è¿‡min_countæ¬¡ï¼Œè‡ªåŠ¨åº”ç”¨
        - è¿”å›ä¿®æ­£åçš„æ•°æ®

        Args:
            ocr_data: OCRè¯†åˆ«çš„åŸå§‹æ•°æ®
            min_count: æœ€å°å‡ºç°æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡

        Returns:
            ä¿®æ­£åçš„æ•°æ®å­—å…¸ï¼ŒåŒ…å«_auto_correctionsåˆ—è¡¨
        """
        corrected_data = ocr_data.copy()
        auto_corrections = []

        # è·å–æ‰€æœ‰å­—æ®µçš„é«˜é¢‘ä¿®æ­£æ¨¡å¼
        field_names = [
            'drawing_number', 'customer_name', 'product_name', 'customer_part_number',
            'material', 'outer_diameter', 'length', 'weight',
            'tolerance', 'surface_roughness', 'heat_treatment', 'surface_treatment'
        ]

        for field_name in field_names:
            original_value = ocr_data.get(field_name)
            if not original_value:
                continue

            # æ ‡å‡†åŒ–åŸå§‹å€¼ç”¨äºåŒ¹é…
            original_str = str(original_value).strip().lower()

            # æŸ¥è¯¢è¯¥å­—æ®µçš„é«˜é¢‘ä¿®æ­£æ¨¡å¼
            patterns = self.get_field_patterns(field_name, min_count=min_count)

            for pattern in patterns:
                pattern_ocr_value = (pattern.get('ocr_value') or '').strip().lower()

                # å¦‚æœOCRå€¼åŒ¹é…å†å²æ¨¡å¼
                if pattern_ocr_value and pattern_ocr_value == original_str:
                    corrected_value = pattern.get('corrected_value', '')
                    if corrected_value and corrected_value != str(original_value):
                        corrected_data[field_name] = corrected_value
                        auto_corrections.append({
                            'field': field_name,
                            'original': str(original_value),
                            'corrected': corrected_value,
                            'pattern_count': pattern.get('count', 0),
                            'source': 'learned_pattern'
                        })
                        logger.info(f"ğŸ¤– è‡ªåŠ¨ä¿®æ­£ [{field_name}]: '{original_value}' â†’ '{corrected_value}' (åŸºäº{pattern.get('count', 0)}æ¬¡å†å²ä¿®æ­£)")
                        break  # æ¯ä¸ªå­—æ®µåªåº”ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ¨¡å¼

        # ç„¶ååº”ç”¨æ™ºèƒ½è§„åˆ™ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        smart_corrected = self.apply_smart_rules(corrected_data)

        # åˆå¹¶æ™ºèƒ½è§„åˆ™çš„ä¿®æ­£
        if smart_corrected.get('_auto_corrections'):
            auto_corrections.extend(smart_corrected['_auto_corrections'])
            del smart_corrected['_auto_corrections']

        # æ–¹æ¡ˆCï¼šå‘é‡æ£€ç´¢å¢å¼ºï¼ˆå¯¹æœªä¿®æ­£çš„å­—æ®µå°è¯•å‘é‡æ£€ç´¢ï¼‰
        try:
            vector_store = _get_vector_store()
            if vector_store:
                already_corrected_fields = {c['field'] for c in auto_corrections}
                for field_name in field_names:
                    if field_name in already_corrected_fields:
                        continue  # å·²ç»è¢«ä¿®æ­£çš„å­—æ®µè·³è¿‡
                    original_value = ocr_data.get(field_name)
                    if not original_value:
                        continue
                    # å‘é‡æ£€ç´¢å»ºè®®
                    suggested = vector_store.get_suggested_correction(
                        field_name=field_name,
                        ocr_value=str(original_value),
                        min_similarity=0.85  # é«˜é˜ˆå€¼ï¼Œç¡®ä¿å‡†ç¡®æ€§
                    )
                    if suggested and suggested != str(original_value):
                        smart_corrected[field_name] = suggested
                        auto_corrections.append({
                            'field': field_name,
                            'original': str(original_value),
                            'corrected': suggested,
                            'source': 'vector_search'
                        })
                        logger.info(f"ğŸ” å‘é‡æ£€ç´¢ä¿®æ­£ [{field_name}]: '{original_value}' â†’ '{suggested}'")
        except Exception as e:
            logger.warning(f"âš ï¸  å‘é‡æ£€ç´¢å¢å¼ºå¤±è´¥: {e}")

        smart_corrected['_auto_corrections'] = auto_corrections
        smart_corrected['_correction_count'] = len(auto_corrections)

        if auto_corrections:
            logger.info(f"âœ… è‡ªåŠ¨ä¿®æ­£å®Œæˆï¼Œå…±ä¿®æ­£ {len(auto_corrections)} ä¸ªå­—æ®µ")
        else:
            logger.info("âœ… æ— éœ€è‡ªåŠ¨ä¿®æ­£ï¼ŒOCRç»“æœå·²å‡†ç¡®")

        return smart_corrected


def get_ocr_learning_service(db: Session) -> OCRLearningService:
    """è·å–OCRå­¦ä¹ æœåŠ¡å®ä¾‹"""
    return OCRLearningService(db)
