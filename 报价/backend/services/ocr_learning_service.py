# services/ocr_learning_service.py
"""
OCRå­¦ä¹ ä¼˜åŒ–æœåŠ¡
å®ç°æ™ºèƒ½è§„åˆ™éªŒè¯å’ŒPromptåŠ¨æ€ä¼˜åŒ–
"""
from typing import Dict, List, Optional, Tuple
from sqlalchemy.orm import Session
from models.ocr_correction import OCRCorrection
from difflib import SequenceMatcher
import re
import logging

logger = logging.getLogger(__name__)


class OCRLearningService:
    """OCRæ™ºèƒ½å­¦ä¹ æœåŠ¡"""

    # æ™ºèƒ½è§„åˆ™åº“
    SMART_RULES = {
        # ææ–™æ ‡å‡†åŒ–è§„åˆ™
        'material': {
            'patterns': [
                (r'sus\s*303', 'SUS303', re.IGNORECASE),
                (r'sus\s*304', 'SUS304', re.IGNORECASE),
                (r'45\s*#', '45#', re.IGNORECASE),
                (r'45å·é’¢', '45#', re.IGNORECASE),
                (r'6061\s*é“', '6061é“åˆé‡‘', re.IGNORECASE),
                (r's45c', 'S45C', re.IGNORECASE),
                (r'stainless\s*steel', 'ä¸é”ˆé’¢', re.IGNORECASE),
            ],
            'validator': lambda x: x and len(x.strip()) > 0
        },

        # ç›´å¾„æ•°å€¼è§„åˆ™ï¼ˆæ¸…ç†éæ•°å­—å­—ç¬¦ï¼‰
        'outer_diameter': {
            'patterns': [
                (r'[Ï†Î¦Ã˜]\s*(\d+\.?\d*)', r'\1', 0),  # ç§»é™¤ç›´å¾„ç¬¦å·
                (r'(\d+\.?\d*)\s*mm', r'\1', re.IGNORECASE),  # ç§»é™¤å•ä½
            ],
            'validator': lambda x: x and re.match(r'^\d+\.?\d*$', str(x))
        },

        # é•¿åº¦æ•°å€¼è§„åˆ™
        'length': {
            'patterns': [
                (r'(\d+\.?\d*)\s*mm', r'\1', re.IGNORECASE),
                (r'é•¿åº¦?\s*[:ï¼š]?\s*(\d+\.?\d*)', r'\1', re.IGNORECASE),
            ],
            'validator': lambda x: x and re.match(r'^\d+\.?\d*$', str(x))
        },

        # å…¬å·®è§„åˆ™
        'tolerance': {
            'patterns': [
                (r'[Â±]\s*(\d+\.?\d*)', r'Â±\1', 0),
                (r'IT\s*(\d+)', r'IT\1', re.IGNORECASE),
                (r'H\s*(\d+)', r'H\1', re.IGNORECASE),
            ],
            'validator': lambda x: x and (re.match(r'Â±\d+\.?\d*', str(x)) or re.match(r'IT\d+', str(x), re.IGNORECASE) or re.match(r'H\d+', str(x), re.IGNORECASE))
        },

        # è¡¨é¢ç²—ç³™åº¦è§„åˆ™
        'surface_roughness': {
            'patterns': [
                (r'Ra\s*(\d+\.?\d*)', r'Ra\1', re.IGNORECASE),
                (r'â–½\s*(\d+\.?\d*)', r'Ra\1', 0),
            ],
            'validator': lambda x: x and re.match(r'Ra\d+\.?\d*', str(x), re.IGNORECASE)
        },
    }

    def __init__(self, db: Session):
        self.db = db

    def apply_smart_rules(self, ocr_data: Dict) -> Dict:
        """
        åº”ç”¨æ™ºèƒ½è§„åˆ™å¯¹OCRç»“æœè¿›è¡Œè‡ªåŠ¨ä¿®æ­£

        Args:
            ocr_data: OCRè¯†åˆ«çš„åŸå§‹æ•°æ®

        Returns:
            ä¿®æ­£åçš„æ•°æ®å­—å…¸
        """
        corrected_data = ocr_data.copy()
        corrections_applied = []

        for field_name, rules in self.SMART_RULES.items():
            if field_name not in corrected_data or not corrected_data[field_name]:
                continue

            original_value = str(corrected_data[field_name])
            corrected_value = original_value

            # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢è§„åˆ™
            for pattern, replacement, flags in rules.get('patterns', []):
                corrected_value = re.sub(pattern, replacement, corrected_value, flags=flags)

            # éªŒè¯ä¿®æ­£åçš„å€¼
            validator = rules.get('validator')
            if validator and not validator(corrected_value):
                # éªŒè¯å¤±è´¥ï¼Œä¿æŒåŸå€¼
                continue

            # å¦‚æœå€¼å‘ç”Ÿäº†å˜åŒ–ï¼Œè®°å½•ä¿®æ­£
            if corrected_value != original_value:
                corrected_data[field_name] = corrected_value
                corrections_applied.append({
                    'field': field_name,
                    'original': original_value,
                    'corrected': corrected_value,
                    'rule': 'smart_rule'
                })
                logger.info(f"ğŸ¤– æ™ºèƒ½è§„åˆ™ä¿®æ­£ [{field_name}]: '{original_value}' â†’ '{corrected_value}'")

        corrected_data['_auto_corrections'] = corrections_applied
        return corrected_data

    def record_correction(
        self,
        drawing_id: int,
        field_name: str,
        ocr_value: Optional[str],
        corrected_value: str
    ) -> OCRCorrection:
        """
        è®°å½•äººå·¥ä¿®æ­£æ•°æ®

        Args:
            drawing_id: å›¾çº¸ID
            field_name: å­—æ®µå
            ocr_value: OCRè¯†åˆ«çš„åŸå§‹å€¼
            corrected_value: äººå·¥ä¿®æ­£åçš„å€¼

        Returns:
            OCRCorrectionè®°å½•
        """
        # è®¡ç®—ä¿®æ­£ç±»å‹å’Œç›¸ä¼¼åº¦
        correction_type, similarity = self._analyze_correction(ocr_value, corrected_value)

        correction = OCRCorrection(
            drawing_id=drawing_id,
            field_name=field_name,
            ocr_value=ocr_value,
            corrected_value=corrected_value,
            correction_type=correction_type,
            similarity_score=similarity
        )

        self.db.add(correction)
        self.db.commit()

        logger.info(f"ğŸ“ è®°å½•ä¿®æ­£: [{field_name}] {ocr_value} â†’ {corrected_value} (ç±»å‹: {correction_type}, ç›¸ä¼¼åº¦: {similarity:.2f})")

        return correction

    def _analyze_correction(
        self,
        ocr_value: Optional[str],
        corrected_value: str
    ) -> Tuple[str, float]:
        """
        åˆ†æä¿®æ­£ç±»å‹å’Œç›¸ä¼¼åº¦

        Returns:
            (correction_type, similarity_score)
        """
        if not ocr_value or ocr_value.strip() == '':
            return ('full_error', 0.0)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, str(ocr_value), str(corrected_value)).ratio()

        # åˆ¤æ–­ä¿®æ­£ç±»å‹
        if similarity < 0.3:
            return ('full_error', similarity)
        elif similarity < 0.7:
            return ('partial_error', similarity)
        else:
            return ('format_error', similarity)

    def get_correction_stats(
        self,
        field_name: Optional[str] = None,
        limit: int = 100
    ) -> Dict:
        """
        è·å–ä¿®æ­£ç»Ÿè®¡æ•°æ®

        Args:
            field_name: å¯é€‰ï¼ŒæŒ‡å®šå­—æ®µå
            limit: è¿”å›çš„æœ€å¤§è®°å½•æ•°

        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        query = self.db.query(OCRCorrection)

        if field_name:
            query = query.filter(OCRCorrection.field_name == field_name)

        corrections = query.order_by(OCRCorrection.created_at.desc()).limit(limit).all()

        # ç»Ÿè®¡åˆ†æ
        total = len(corrections)
        if total == 0:
            return {
                'total': 0,
                'by_field': {},
                'by_type': {},
                'avg_similarity': 0
            }

        by_field = {}
        by_type = {}
        total_similarity = 0

        for correction in corrections:
            # æŒ‰å­—æ®µç»Ÿè®¡
            if correction.field_name not in by_field:
                by_field[correction.field_name] = 0
            by_field[correction.field_name] += 1

            # æŒ‰ç±»å‹ç»Ÿè®¡
            if correction.correction_type not in by_type:
                by_type[correction.correction_type] = 0
            by_type[correction.correction_type] += 1

            # ç´¯è®¡ç›¸ä¼¼åº¦
            total_similarity += correction.similarity_score or 0

        return {
            'total': total,
            'by_field': by_field,
            'by_type': by_type,
            'avg_similarity': total_similarity / total if total > 0 else 0,
            'recent_corrections': [
                {
                    'field': c.field_name,
                    'ocr_value': c.ocr_value,
                    'corrected_value': c.corrected_value,
                    'type': c.correction_type,
                    'similarity': c.similarity_score,
                    'created_at': c.created_at.isoformat()
                }
                for c in corrections[:20]  # æœ€è¿‘20æ¡
            ]
        }

    def learn_from_corrections(self) -> Dict:
        """
        ä»ä¿®æ­£æ•°æ®ä¸­å­¦ä¹ ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®

        Returns:
            åŒ…å«å­¦ä¹ ç»“æœå’Œä¼˜åŒ–å»ºè®®çš„å­—å…¸
        """
        stats = self.get_correction_stats(limit=500)

        if stats['total'] < 10:
            return {
                'status': 'insufficient_data',
                'message': f'ä¿®æ­£æ•°æ®ä¸è¶³ï¼ˆå½“å‰: {stats["total"]}ï¼Œéœ€è¦è‡³å°‘10æ¡ï¼‰',
                'suggestions': []
            }

        suggestions = []

        # åˆ†æé«˜é¢‘é”™è¯¯å­—æ®µ
        for field_name, count in stats['by_field'].items():
            if count > stats['total'] * 0.2:  # å æ¯”è¶…è¿‡20%
                suggestions.append({
                    'type': 'high_error_field',
                    'field': field_name,
                    'count': count,
                    'suggestion': f'å­—æ®µ {field_name} é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–Promptä¸­çš„ç›¸å…³æè¿°'
                })

        # åˆ†æé”™è¯¯ç±»å‹åˆ†å¸ƒ
        full_errors = stats['by_type'].get('full_error', 0)
        if full_errors > stats['total'] * 0.3:  # å®Œå…¨é”™è¯¯è¶…è¿‡30%
            suggestions.append({
                'type': 'high_full_error_rate',
                'count': full_errors,
                'suggestion': 'OCRå®Œå…¨è¯†åˆ«é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®å¢å¼ºæ¨¡å‹çš„å›¾çº¸ç†è§£èƒ½åŠ›æˆ–è°ƒæ•´å¸ƒå±€åˆ†æ'
            })

        # å¹³å‡ç›¸ä¼¼åº¦åˆ†æ
        if stats['avg_similarity'] < 0.5:
            suggestions.append({
                'type': 'low_similarity',
                'avg_similarity': stats['avg_similarity'],
                'suggestion': f'å¹³å‡ç›¸ä¼¼åº¦è¾ƒä½ ({stats["avg_similarity"]:.2f})ï¼Œå»ºè®®å…¨é¢ä¼˜åŒ–OCRæ¨¡å‹'
            })

        return {
            'status': 'success',
            'stats': stats,
            'suggestions': suggestions
        }

    def get_field_patterns(self, field_name: str, min_count: int = 3) -> List[Dict]:
        """
        æå–æŸä¸ªå­—æ®µçš„å¸¸è§ä¿®æ­£æ¨¡å¼

        Args:
            field_name: å­—æ®µå
            min_count: æœ€å°å‡ºç°æ¬¡æ•°

        Returns:
            æ¨¡å¼åˆ—è¡¨
        """
        corrections = self.db.query(OCRCorrection).filter(
            OCRCorrection.field_name == field_name
        ).all()

        # ç»Ÿè®¡OCRå€¼åˆ°ä¿®æ­£å€¼çš„æ˜ å°„
        pattern_map = {}
        for c in corrections:
            key = (c.ocr_value or '', c.corrected_value or '')
            if key not in pattern_map:
                pattern_map[key] = 0
            pattern_map[key] += 1

        # è¿‡æ»¤å‡ºé«˜é¢‘æ¨¡å¼
        patterns = [
            {
                'ocr_value': ocr_val,
                'corrected_value': corrected_val,
                'count': count
            }
            for (ocr_val, corrected_val), count in pattern_map.items()
            if count >= min_count
        ]

        # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
        patterns.sort(key=lambda x: x['count'], reverse=True)

        return patterns


def get_ocr_learning_service(db: Session) -> OCRLearningService:
    """è·å–OCRå­¦ä¹ æœåŠ¡å®ä¾‹"""
    return OCRLearningService(db)
