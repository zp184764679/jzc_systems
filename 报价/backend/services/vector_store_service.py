# services/vector_store_service.py
"""
å‘é‡å­˜å‚¨æœåŠ¡ - æ–¹æ¡ˆC
åŸºäºChromaDBå®ç°OCRä¿®æ­£æ¡ˆä¾‹çš„å‘é‡æ£€ç´¢å¢å¼º
"""
import chromadb
from chromadb.config import Settings
from typing import Dict, List, Optional, Tuple
from sqlalchemy.orm import Session
from models.ocr_correction import OCRCorrection
import logging
import os
import json

logger = logging.getLogger(__name__)

# å‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„
CHROMA_PERSIST_DIR = os.path.join(os.path.dirname(__file__), '..', 'data', 'chroma_db')


class VectorStoreService:
    """å‘é‡å­˜å‚¨æœåŠ¡ - ç”¨äºOCRä¿®æ­£æ¡ˆä¾‹çš„è¯­ä¹‰æ£€ç´¢"""

    def __init__(self, db: Session = None):
        self.db = db
        self._client = None
        self._collection = None
        self._embedding_model = None

    @property
    def client(self):
        """æ‡’åŠ è½½ChromaDBå®¢æˆ·ç«¯"""
        if self._client is None:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(CHROMA_PERSIST_DIR, exist_ok=True)

            self._client = chromadb.PersistentClient(
                path=CHROMA_PERSIST_DIR,
                settings=Settings(anonymized_telemetry=False)
            )
            logger.info(f"âœ… ChromaDBåˆå§‹åŒ–æˆåŠŸ: {CHROMA_PERSIST_DIR}")
        return self._client

    @property
    def collection(self):
        """è·å–OCRä¿®æ­£æ¡ˆä¾‹é›†åˆ"""
        if self._collection is None:
            self._collection = self.client.get_or_create_collection(
                name="ocr_corrections",
                metadata={"description": "OCRä¿®æ­£æ¡ˆä¾‹å‘é‡åº“"}
            )
            logger.info(f"âœ… é›†åˆå·²åŠ è½½: ocr_corrections (å…±{self._collection.count()}æ¡è®°å½•)")
        return self._collection

    @property
    def embedding_model(self):
        """æ‡’åŠ è½½åµŒå…¥æ¨¡å‹"""
        if self._embedding_model is None:
            try:
                from sentence_transformers import SentenceTransformer
                # ä½¿ç”¨è½»é‡çº§å¤šè¯­è¨€æ¨¡å‹
                self._embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                logger.info("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ: paraphrase-multilingual-MiniLM-L12-v2")
            except Exception as e:
                logger.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise
        return self._embedding_model

    def _generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        if not text or not text.strip():
            return None
        embedding = self.embedding_model.encode(text, convert_to_numpy=True)
        return embedding.tolist()

    def _create_correction_text(self, field_name: str, ocr_value: str, corrected_value: str) -> str:
        """åˆ›å»ºç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬"""
        return f"å­—æ®µ:{field_name} OCRè¯†åˆ«:{ocr_value} ä¿®æ­£ä¸º:{corrected_value}"

    def add_correction(self, correction: OCRCorrection) -> bool:
        """
        æ·»åŠ ä¿®æ­£æ¡ˆä¾‹åˆ°å‘é‡åº“

        Args:
            correction: OCRCorrectionå¯¹è±¡

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»ºæ–‡æ¡£æ–‡æœ¬
            doc_text = self._create_correction_text(
                correction.field_name,
                correction.ocr_value or '',
                correction.corrected_value or ''
            )

            # ç”Ÿæˆå‘é‡
            embedding = self._generate_embedding(doc_text)
            if embedding is None:
                logger.warning(f"âš ï¸  æ— æ³•ç”Ÿæˆå‘é‡: correction_id={correction.id}")
                return False

            # æ·»åŠ åˆ°é›†åˆ
            self.collection.add(
                ids=[f"correction_{correction.id}"],
                embeddings=[embedding],
                documents=[doc_text],
                metadatas=[{
                    "correction_id": correction.id,
                    "drawing_id": correction.drawing_id,
                    "field_name": correction.field_name,
                    "ocr_value": correction.ocr_value or '',
                    "corrected_value": correction.corrected_value or '',
                    "correction_type": correction.correction_type or '',
                    "similarity_score": correction.similarity_score or 0.0
                }]
            )

            logger.info(f"âœ… ä¿®æ­£æ¡ˆä¾‹å·²æ·»åŠ åˆ°å‘é‡åº“: correction_id={correction.id}")
            return True

        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ä¿®æ­£æ¡ˆä¾‹å¤±è´¥: {e}")
            return False

    def search_similar_corrections(
        self,
        field_name: str,
        ocr_value: str,
        top_k: int = 5,
        min_similarity: float = 0.7
    ) -> List[Dict]:
        """
        æœç´¢ç›¸ä¼¼çš„ä¿®æ­£æ¡ˆä¾‹

        Args:
            field_name: å­—æ®µå
            ocr_value: OCRè¯†åˆ«å€¼
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„kæ¡è®°å½•
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            ç›¸ä¼¼ä¿®æ­£æ¡ˆä¾‹åˆ—è¡¨
        """
        try:
            # åˆ›å»ºæŸ¥è¯¢æ–‡æœ¬
            query_text = self._create_correction_text(field_name, ocr_value, '')
            query_embedding = self._generate_embedding(query_text)

            if query_embedding is None:
                return []

            # æ‰§è¡Œå‘é‡æ£€ç´¢
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                where={"field_name": field_name},  # åªæœç´¢åŒä¸€å­—æ®µ
                include=["documents", "metadatas", "distances"]
            )

            if not results or not results['ids'] or not results['ids'][0]:
                return []

            # å¤„ç†ç»“æœ
            similar_corrections = []
            for i, doc_id in enumerate(results['ids'][0]):
                # ChromaDBè¿”å›çš„æ˜¯è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦
                distance = results['distances'][0][i] if results['distances'] else 1.0
                similarity = 1.0 / (1.0 + distance)  # è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜

                if similarity >= min_similarity:
                    metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                    similar_corrections.append({
                        'correction_id': metadata.get('correction_id'),
                        'field_name': metadata.get('field_name'),
                        'ocr_value': metadata.get('ocr_value'),
                        'corrected_value': metadata.get('corrected_value'),
                        'similarity': round(similarity, 4),
                        'source': 'vector_search'
                    })

            logger.info(f"ğŸ” å‘é‡æ£€ç´¢å®Œæˆ: field={field_name}, ocr_value={ocr_value[:20]}..., æ‰¾åˆ°{len(similar_corrections)}æ¡ç›¸ä¼¼è®°å½•")
            return similar_corrections

        except Exception as e:
            logger.error(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return []

    def sync_from_database(self) -> int:
        """
        ä»æ•°æ®åº“åŒæ­¥ä¿®æ­£æ¡ˆä¾‹åˆ°å‘é‡åº“

        Returns:
            åŒæ­¥çš„è®°å½•æ•°
        """
        if not self.db:
            logger.error("âŒ æ•°æ®åº“ä¼šè¯æœªè®¾ç½®")
            return 0

        try:
            # è·å–æ‰€æœ‰ä¿®æ­£è®°å½•
            corrections = self.db.query(OCRCorrection).all()

            # è·å–å·²æœ‰çš„ID
            existing_ids = set()
            try:
                existing = self.collection.get()
                if existing and existing['ids']:
                    existing_ids = set(existing['ids'])
            except:
                pass

            synced = 0
            for correction in corrections:
                doc_id = f"correction_{correction.id}"
                if doc_id not in existing_ids:
                    if self.add_correction(correction):
                        synced += 1

            logger.info(f"âœ… å‘é‡åº“åŒæ­¥å®Œæˆ: æ–°å¢{synced}æ¡ï¼Œæ€»è®¡{self.collection.count()}æ¡")
            return synced

        except Exception as e:
            logger.error(f"âŒ å‘é‡åº“åŒæ­¥å¤±è´¥: {e}")
            return 0

    def get_suggested_correction(
        self,
        field_name: str,
        ocr_value: str,
        min_similarity: float = 0.8
    ) -> Optional[str]:
        """
        è·å–å»ºè®®çš„ä¿®æ­£å€¼

        Args:
            field_name: å­—æ®µå
            ocr_value: OCRè¯†åˆ«å€¼
            min_similarity: æœ€å°ç›¸ä¼¼åº¦

        Returns:
            å»ºè®®çš„ä¿®æ­£å€¼ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        similar = self.search_similar_corrections(
            field_name=field_name,
            ocr_value=ocr_value,
            top_k=3,
            min_similarity=min_similarity
        )

        if not similar:
            return None

        # è¿”å›æœ€ç›¸ä¼¼çš„ä¿®æ­£å€¼
        best_match = similar[0]
        logger.info(f"ğŸ¯ å‘é‡æ£€ç´¢å»ºè®®: {field_name}='{ocr_value}' â†’ '{best_match['corrected_value']}' (ç›¸ä¼¼åº¦: {best_match['similarity']})")
        return best_match['corrected_value']


# å…¨å±€å•ä¾‹
_vector_store = None


def get_vector_store_service(db: Session = None) -> VectorStoreService:
    """è·å–å‘é‡å­˜å‚¨æœåŠ¡å®ä¾‹"""
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStoreService(db)
    elif db is not None:
        _vector_store.db = db
    return _vector_store
